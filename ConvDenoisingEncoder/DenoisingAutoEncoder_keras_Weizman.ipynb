{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenoisingAutoEncoder_keras_Weizman.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ConSurv/HABP/blob/master/ConvDenoisingEncoder/DenoisingAutoEncoder_keras_Weizman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9ASNzmGCO8p",
        "colab_type": "code",
        "outputId": "7235fac7-f084-4321-c7ba-69262277db8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHgU9Nz3cpsH",
        "colab_type": "code",
        "outputId": "ad885b75-cd7f-4d0f-e2ff-cb6fc0c17f15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "print(GPUs)\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=59d6111123e5fb8f45e482cb113043c00f3f8683bb038fea496c3589ed6a5c51\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "[<GPUtil.GPUtil.GPU object at 0x7f716e45a710>]\n",
            "Gen RAM Free: 26.3 GB  | Proc size: 158.5 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQbRxdtoNaPQ",
        "colab_type": "code",
        "outputId": "e6385d5c-ba7a-4ff0-d54e-f09edd546500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "! pip install keras_layer_normalization"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_layer_normalization\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_layer_normalization) (1.18.3)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_layer_normalization) (2.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_layer_normalization) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_layer_normalization) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_layer_normalization) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_layer_normalization) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_layer_normalization) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_layer_normalization) (1.12.0)\n",
            "Building wheels for collected packages: keras-layer-normalization\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=cc7e437536e881f9ffc490f9a099b959f9a695d406a9209840aae77e3e9ba51c\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
            "Successfully built keras-layer-normalization\n",
            "Installing collected packages: keras-layer-normalization\n",
            "Successfully installed keras-layer-normalization-0.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmiwzhxyMUFz",
        "colab_type": "code",
        "outputId": "b74ed29b-794f-458c-d6e1-fcf351b4f9fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D , MaxPooling2D,UpSampling2D\n",
        "from keras.models import Sequential, load_model\n",
        "from keras_layer_normalization import LayerNormalization\n",
        "from os import listdir\n",
        "from os.path import isfile, join, isdir\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import shelve\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJgTwrx9NwKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "    DATASET_PATH = \"/content/drive/My Drive/FYP_MODEL/behavior_data\".replace('\\\\', '/')\n",
        "    BATCH_SIZE = 6\n",
        "    EPOCHS = 10\n",
        "    MODEL_PATH = \"/content/drive/My Drive/FYP_MODEL/models/behav_model.hdf5\".replace('\\\\', '/')\n",
        "    noise_factor = 0.5\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VVm4hoZbBQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clips_by_stride(stride, frames_list, sequence_size):\n",
        "    \"\"\" For data augmenting purposes.\n",
        "    Parameters\n",
        "    ----------\n",
        "    stride : int\n",
        "        The desired distance between two consecutive frames\n",
        "    frames_list : list\n",
        "        A list of sorted frames of shape 256 X 256\n",
        "    sequence_size: int\n",
        "        The size of the desired LSTM sequence\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of clips , 10 frames each\n",
        "    \"\"\"\n",
        "    clips = []\n",
        "    sz = len(frames_list)\n",
        "    clip = np.zeros(shape=(sequence_size, 256, 256, 1))\n",
        "    cnt = 0\n",
        "    for start in range(0, stride):\n",
        "        for i in range(start, sz, stride):\n",
        "            clip[cnt, :, :, 0] = frames_list[i]\n",
        "            cnt = cnt + 1\n",
        "            if cnt == sequence_size:\n",
        "                clips.append(clip)\n",
        "                cnt = 0\n",
        "    # print(len(clips))\n",
        "    # print(np.array(clips).shape)\n",
        "    return clips\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pljuNEaQbHK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_training_set():\n",
        "    \"\"\"\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of training sequences of shape (NUMBER_OF_SEQUENCES,SINGLE_SEQUENCE_SIZE,FRAME_WIDTH,FRAME_HEIGHT,1)\n",
        "    \"\"\"\n",
        "    #####################################\n",
        "    # cache = shelve.open(Config.CACHE_PATH)\n",
        "    # return cache[\"datasetLSTM\"]\n",
        "    #####################################\n",
        "    clips = []\n",
        "    noise_clips = []\n",
        "    labels = []\n",
        "    # loop over the training folders (bend,jack....)\n",
        "    for category in sorted(listdir(Config.DATASET_PATH)):\n",
        "      # (/bend)\n",
        "      if isdir(join(Config.DATASET_PATH, category)):\n",
        "        label = category\n",
        "        path = join(Config.DATASET_PATH,category)\n",
        "        for subcat in sorted(listdir(path)):\n",
        "            # sub-category= (daria_bend,denis_bend....)\n",
        "            path1 = join(path,subcat)\n",
        "            all_frames = []\n",
        "            noise_all_frames = []\n",
        "            for frame in sorted(listdir(path1)):\n",
        "              if str(join(path1,frame))[-3:] == \"jpg\":\n",
        "                imagepath = join(path1,frame)\n",
        "                image = cv2.imread(imagepath)\n",
        "                imageresize = cv2.resize(image, (256, 256), interpolation = cv2.INTER_AREA)\n",
        "                img = cv2.cvtColor(imageresize, cv2.COLOR_BGR2GRAY)\n",
        "                img1 = np.array(img, dtype=np.float32)/256.0\n",
        "                noise_img = img1 + Config.noise_factor + np.random.rand(256,256)\n",
        "                all_frames.append(img1)\n",
        "                noise_all_frames.append(noise_img) \n",
        "                \n",
        "            # get the 10-frames sequences from the list of images after applying data augmentation\n",
        "            for stride in range(1, 2):\n",
        "              frames = get_clips_by_stride(stride=1, frames_list=all_frames, sequence_size=15)\n",
        "              noise_frames = get_clips_by_stride(stride=1, frames_list=noise_all_frames, sequence_size=15)\n",
        "              clips.extend(frames)\n",
        "              noise_clips.extend(noise_frames) \n",
        "              for i in range(0,len(frames)):\n",
        "                labels.append(label)\n",
        "\n",
        "    return clips,noise_clips,labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxYh01tKN_BR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(reload_model=True):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    reload_model : bool\n",
        "        Load saved model or retrain it\n",
        "    \"\"\"\n",
        "    if not reload_model:\n",
        "        return load_model(Config.MODEL_PATH, custom_objects={'LayerNormalization': LayerNormalization})\n",
        "   \n",
        "    seq = Sequential()\n",
        "    print(\"Model initialized\")\n",
        "\n",
        "    #################Encoder###############\n",
        "    seq.add(\n",
        "        TimeDistributed(Conv2D(128, (11, 11), strides=4, padding=\"same\"), batch_input_shape=(None, 15, 256, 256, 1)))\n",
        "    seq.add(LayerNormalization())\n",
        "\n",
        "    seq.add(TimeDistributed(MaxPooling2D()))\n",
        "\n",
        "    seq.add(TimeDistributed(Conv2D(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "\n",
        "    seq.add(TimeDistributed(MaxPooling2D()))\n",
        "     \n",
        "    # # # # #\n",
        "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    # Code\n",
        "    seq.add(ConvLSTM2D(16, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "    \n",
        "    seq.add(ConvLSTM2D(32, (3, 3), padding=\"same\", return_sequences=True))\n",
        "    seq.add(LayerNormalization())\n",
        "\n",
        "    ###########DECODER###############\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "\n",
        "    seq.add(TimeDistributed(UpSampling2D()))\n",
        "\n",
        "    seq.add(TimeDistributed(Conv2DTranspose(64, (11, 11), strides=4, padding=\"same\")))\n",
        "    seq.add(LayerNormalization())\n",
        "\n",
        "    seq.add(TimeDistributed(UpSampling2D()))\n",
        "\n",
        "    seq.add(TimeDistributed(Conv2D(1, (11, 11), activation=\"sigmoid\", padding=\"same\")))\n",
        "    print(seq.summary())\n",
        "    seq.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=1e-4, decay=1e-5, epsilon=1e-6))\n",
        "    \n",
        "    return seq\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCC_uzKybQeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "from sklearn.model_selection import train_test_split\n",
        "def evaluate(train_set, noise_train_set, validation_set, noise_validation_set):\n",
        "    model = get_model(True)\n",
        "    print(\"got model\")\n",
        "\n",
        "    # fit the model\n",
        "    hist = model.fit(noise_train_set, train_set,\n",
        "            batch_size=Config.BATCH_SIZE, epochs=Config.EPOCHS, shuffle=False,\n",
        "            validation_data=(noise_validation_set, validation_set))\n",
        "    model.save(Config.MODEL_PATH)\n",
        "    return hist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVD1FrwPXsiA",
        "colab_type": "code",
        "outputId": "d0567084-04c1-4629-d077-5b5cb7b02581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# get training data\n",
        "print(\"Fetching dataset.........\")\n",
        "train_set, noise_train_set, labels = get_training_set()\n",
        "train_set = np.array(train_set)\n",
        "noise_train_set = np.array(noise_train_set)\n",
        "print(\"Completed Fetching!!!\")\n",
        "train_labels = np.zeros(len(labels))\n",
        "# print(labels)\n",
        "for i in range(len(labels)):\n",
        "  if labels[i]==\"bend\":\n",
        "    train_labels[i] = 0\n",
        "  elif labels[i]==\"jack\":\n",
        "    train_labels[i] = 1\n",
        "  elif labels[i]==\"jump\":\n",
        "    train_labels[i] = 2\n",
        "  elif labels[i]==\"pjump\":\n",
        "    train_labels[i] = 3\n",
        "  elif labels[i]==\"run\":\n",
        "    train_labels[i] = 4\n",
        "  elif labels[i]==\"side\":\n",
        "    train_labels[i] = 5\n",
        "  elif labels[i]==\"walk\":\n",
        "    train_labels[i] = 6\n",
        "  elif labels[i]==\"wave1\":\n",
        "    train_labels[i] = 7\n",
        "  elif labels[i]==\"wave2\":\n",
        "    train_labels[i] = 8\n",
        "  else:\n",
        "    train_labels[i] = 9\n",
        "print(\"labels generated......\")\n",
        "\n",
        "# Save training images and labels in a numpy array\n",
        "np.save('/content/drive/My Drive/FYP_MODEL/numpy_training_datasets/behavior/Behav_images.npy', train_set)\n",
        "np.save('/content/drive/My Drive/FYP_MODEL/numpy_training_datasets/behavior/Behav_noise_images.npy', noise_train_set)\n",
        "np.save('/content/drive/My Drive/FYP_MODEL/numpy_training_datasets/behavior/Behav_labels.npy', train_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching dataset.........\n",
            "Completed Fetching!!!\n",
            "labels generated......\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GiHwZUyqrgy",
        "colab_type": "code",
        "outputId": "5f019f31-a619-4f44-8b8f-f618a92f6040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(noise_train_set.shape)\n",
        "print(train_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(297, 15, 256, 256, 1)\n",
            "(297,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goNiaIu-vlFR",
        "colab_type": "code",
        "outputId": "840e964a-b1de-4484-e7f4-f455841588b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "import numpy as np\n",
        "# Load training images and labels that are stored in numpy array\n",
        "train_set = np.load('/content/drive/My Drive/FYP_MODEL/numpy_training_datasets/behavior/Behav_images.npy')\n",
        "noise_train_set = np.load('/content/drive/My Drive/FYP_MODEL/numpy_training_datasets/behavior/Behav_noise_images.npy')\n",
        "train_labels =np.load('/content/drive/My Drive/FYP_MODEL/numpy_training_datasets/behavior/Behav_labels.npy')\n",
        "\n",
        "print(train_set.shape)\n",
        "print(noise_train_set.shape)\n",
        "print(train_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7d58437fc33b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Load training images and labels that are stored in numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/FYP_MODEL/numpy_training_datasets/behavior/Behav_images.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnoise_train_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/FYP_MODEL/numpy_training_datasets/behavior/Behav_noise_images.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/FYP_MODEL/numpy_training_datasets/behavior/Behav_labels.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/FYP_MODEL/numpy_training_datasets/behavior/Behav_images.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQIb7ZTyAMq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# spliting testing dataset\n",
        "train_set, test_set, noise_train_set, noise_test_set, train_labels, test_labels =  train_test_split(train_set, noise_train_set, train_labels, test_size=0.1, random_state=4)\n",
        "train_set, validation_set, noise_train_set, noise_validation_set, train_labels, validation_labels =  train_test_split(train_set, noise_train_set, train_labels, test_size=0.1, random_state=4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "279p3J5DGepj",
        "colab_type": "code",
        "outputId": "78bc7829-6507-4e69-ec42-09c160bc93f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hist= evaluate(train_set, noise_train_set, validation_set, noise_validation_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialized\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed_1 (TimeDist (None, 15, 64, 64, 128)   15616     \n",
            "_________________________________________________________________\n",
            "layer_normalization_1 (Layer (None, 15, 64, 64, 128)   256       \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 15, 32, 32, 128)   0         \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 15, 16, 16, 64)    204864    \n",
            "_________________________________________________________________\n",
            "layer_normalization_2 (Layer (None, 15, 16, 16, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 15, 8, 8, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_1 (ConvLSTM2D)  (None, 15, 8, 8, 32)      110720    \n",
            "_________________________________________________________________\n",
            "layer_normalization_3 (Layer (None, 15, 8, 8, 32)      64        \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_2 (ConvLSTM2D)  (None, 15, 8, 8, 16)      27712     \n",
            "_________________________________________________________________\n",
            "layer_normalization_4 (Layer (None, 15, 8, 8, 16)      32        \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_3 (ConvLSTM2D)  (None, 15, 8, 8, 32)      55424     \n",
            "_________________________________________________________________\n",
            "layer_normalization_5 (Layer (None, 15, 8, 8, 32)      64        \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 15, 16, 16, 64)    51264     \n",
            "_________________________________________________________________\n",
            "layer_normalization_6 (Layer (None, 15, 16, 16, 64)    128       \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 15, 32, 32, 64)    0         \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 15, 128, 128, 64)  495680    \n",
            "_________________________________________________________________\n",
            "layer_normalization_7 (Layer (None, 15, 128, 128, 64)  128       \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 15, 256, 256, 64)  0         \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 15, 256, 256, 1)   7745      \n",
            "=================================================================\n",
            "Total params: 969,825\n",
            "Trainable params: 969,825\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "got model\n",
            "Train on 240 samples, validate on 27 samples\n",
            "Epoch 1/10\n",
            "240/240 [==============================] - 66s 274ms/step - loss: 0.0382 - val_loss: 0.0263\n",
            "Epoch 2/10\n",
            "240/240 [==============================] - 50s 209ms/step - loss: 0.0227 - val_loss: 0.0240\n",
            "Epoch 3/10\n",
            "240/240 [==============================] - 50s 209ms/step - loss: 0.0214 - val_loss: 0.0241\n",
            "Epoch 4/10\n",
            "240/240 [==============================] - 50s 209ms/step - loss: 0.0209 - val_loss: 0.0233\n",
            "Epoch 5/10\n",
            "240/240 [==============================] - 50s 209ms/step - loss: 0.0206 - val_loss: 0.0230\n",
            "Epoch 6/10\n",
            "240/240 [==============================] - 50s 209ms/step - loss: 0.0206 - val_loss: 0.0220\n",
            "Epoch 7/10\n",
            "240/240 [==============================] - 50s 209ms/step - loss: 0.0204 - val_loss: 0.0209\n",
            "Epoch 8/10\n",
            "240/240 [==============================] - 50s 209ms/step - loss: 0.0194 - val_loss: 0.0192\n",
            "Epoch 9/10\n",
            "240/240 [==============================] - 50s 208ms/step - loss: 0.0173 - val_loss: 0.0150\n",
            "Epoch 10/10\n",
            "240/240 [==============================] - 50s 208ms/step - loss: 0.0136 - val_loss: 0.0131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbwdyYwpsxa2",
        "colab_type": "code",
        "outputId": "f838b56c-a6a9-4e8a-aa5f-349f8bbe695e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_values = hist.history['loss']\n",
        "loss_val = hist.history['val_loss']\n",
        "epochs = range(1, len(loss_values)+1)\n",
        "\n",
        "plt.plot(epochs, loss_values, label='Training Loss')\n",
        "plt.plot(epochs, loss_val, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3gn5eHoXIFh",
        "colab_type": "code",
        "outputId": "2d2a30aa-1e5f-42e7-a3f0-d5465089b9e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "# modify model upto code layer\n",
        "model = get_model(False)\n",
        "modules = model.layers[:-9]\n",
        "new_model = Sequential(modules)\n",
        "\n",
        "# extract code features\n",
        "train_features = new_model.predict(noise_train_set, batch_size = 4)\n",
        "test_features = new_model.predict(noise_test_set, batch_size = 4)\n",
        "validation_features = new_model.predict(noise_validation_set, batch_size = 4)\n",
        "\n",
        "print(train_features.shape)\n",
        "print(test_features.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)\n",
        "print(validation_features.shape)\n",
        "print(validation_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(240, 15, 8, 8, 16)\n",
            "(30, 15, 8, 8, 16)\n",
            "(240,)\n",
            "(30,)\n",
            "(27, 15, 8, 8, 16)\n",
            "(27,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvI4Rqm-YlUc",
        "colab_type": "code",
        "outputId": "0be9d1aa-d9ca-43ec-cdf0-7f3a0b9e1c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_features = train_features.reshape(378,10*8*8*16)\n",
        "test_features = test_features.reshape(47,10*8*8*16)\n",
        "validation_features = validation_features.reshape(43,10*8*8*16)\n",
        "\n",
        "\n",
        "print(train_features.shape)\n",
        "print(test_features.shape)\n",
        "\n",
        "np.save('/content/drive/My Drive/FYP_MODEL/numpy_training_datasets/Behav/train_features.npy', train_features)\n",
        "np.save('/content/drive/My Drive/FYP_MODEL/numpy_training_datasets/Behav/test_features.npy', test_features)\n",
        "np.save('/content/drive/My Drive/FYP_MODEL/numpy_training_datasets/Behav/validation_features.npy', validation_features)\n",
        "\n",
        "np.save('/content/drive/My Drive/FYP_MODEL/numpy_training_datasets/Behav/train_labels.npy', train_labels)\n",
        "np.save('/content/drive/My Drive/FYP_MODEL/numpy_training_datasets/Behav/test_labels.npy', test_labels)\n",
        "np.save('/content/drive/My Drive/FYP_MODEL/numpy_training_datasets/Behav/validation_labels.npy', validation_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(378, 10240)\n",
            "(47, 10240)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}